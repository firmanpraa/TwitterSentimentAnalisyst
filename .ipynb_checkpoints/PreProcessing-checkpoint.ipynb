{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string as st\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@ummcampus ngadain Kompetisi Karya Kreatif, al...</td>\n",
       "      <td>2019-12-18 08:42:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Banyak banget agenda dari @ummcampus yang dise...</td>\n",
       "      <td>2019-12-18 08:28:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jadi anak bola dulu aja, gitu tahapannya dik w...</td>\n",
       "      <td>2019-12-16 21:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Berbicara HAM berarti kebebasan berekspresi ko...</td>\n",
       "      <td>2019-12-16 16:46:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Aku mau main, tapi ga boleh loh....wkwkwkwkwk</td>\n",
       "      <td>2019-12-16 13:27:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2995</td>\n",
       "      <td>Melalui Prodi Kehutanan Fakultas Pertanian dan...</td>\n",
       "      <td>2019-02-25 07:15:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>Bukannya itu yg kamu mau? Wkwkwk</td>\n",
       "      <td>2019-02-25 02:35:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2997</td>\n",
       "      <td>Duhh jadi takut famous wkwkkwkwkw</td>\n",
       "      <td>2019-02-25 02:33:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2998</td>\n",
       "      <td>Dibaliho depan kampus wkwkwk</td>\n",
       "      <td>2019-02-25 02:31:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2999</td>\n",
       "      <td>Tinggal nunggu direkrut berarti hahaha</td>\n",
       "      <td>2019-02-25 02:30:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text                 date\n",
       "0     @ummcampus ngadain Kompetisi Karya Kreatif, al...  2019-12-18 08:42:09\n",
       "1     Banyak banget agenda dari @ummcampus yang dise...  2019-12-18 08:28:37\n",
       "2     Jadi anak bola dulu aja, gitu tahapannya dik w...  2019-12-16 21:53:03\n",
       "3     Berbicara HAM berarti kebebasan berekspresi ko...  2019-12-16 16:46:40\n",
       "4         Aku mau main, tapi ga boleh loh....wkwkwkwkwk  2019-12-16 13:27:12\n",
       "...                                                 ...                  ...\n",
       "2995  Melalui Prodi Kehutanan Fakultas Pertanian dan...  2019-02-25 07:15:20\n",
       "2996                   Bukannya itu yg kamu mau? Wkwkwk  2019-02-25 02:35:41\n",
       "2997                  Duhh jadi takut famous wkwkkwkwkw  2019-02-25 02:33:28\n",
       "2998                       Dibaliho depan kampus wkwkwk  2019-02-25 02:31:06\n",
       "2999             Tinggal nunggu direkrut berarti hahaha  2019-02-25 02:30:15\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Volumes/MAC HDD/Study/UMM/Semester 5/Fungsional/Twitter/TwitterSentimentAnalisyst/output_got.csv'\n",
    "data = pd.read_csv(path)   \n",
    "dataframe = pd.DataFrame(data, columns= ['text','date'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_tweets(tweets):\n",
    "    lower = tweets.lower()\n",
    "    cleaned_uri = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', lower)\n",
    "    cleaned_user = re.sub(r'@\\w+', '', cleaned_uri)\n",
    "    cleaned_hashtag = re.sub(r'#\\w+', '', cleaned_user)\n",
    "    cleaned_number = re.sub(r'\\d+', '', cleaned_hashtag)\n",
    "    cleaned_punc = cleaned_number.translate(str.maketrans(\"\",\"\",st.punctuation))\n",
    "    empty_spaced = cleaned_punc.replace('\\n','').strip()\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    steamed = stemmer.stem(empty_spaced)\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopword = factory.create_stop_word_remover()\n",
    "    cleaned_tweets = stopword.remove(steamed)\n",
    "    return cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['cleaned_tweets'] = dataframe['text'].apply(preprocessing_tweets)\n",
    "dataframe = dataframe.drop_duplicates(subset=\"cleaned_tweets\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "dataframe = dataframe[dataframe['cleaned_tweets'] != \"\"]\n",
    "dataframe['len'] = [len(x) for x in dataframe.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = dataframe.to_csv(r'/Volumes/MAC HDD/Study/UMM/Semester 5/Fungsional/Twitter/TwitterSentimentAnalisyst/umm_cleaned_2.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
